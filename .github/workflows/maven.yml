name: CI\CD v101
on:
  push:
    branches: ["main", "testSolution"]
  pull_request:
    branches: ["main", "testSolution"]
    types: [opened, synchronize]
  workflow_call:
permissions:
  checks: write
  actions: write
  contents: write
  pull-requests: write
  pages: write
  id-token: write
jobs:
  run-autograding-tests:
    runs-on: ubuntu-latest
    if: github.actor != 'github-classroom[bot]' && (github.event_name != 'push' || github.event.pull_request == null)
    steps:
      - name: Checkout code
        uses: actions/checkout@v4
        with:
          fetch-depth: 0
      - name: Get Latest SHA
        id: get_sha
        run: |
          LATEST_SHA=$(git log -1 --format="%H" --all -- . ':(glob)**/*.java' ':(exclude)**/*Tester.java' 2>/dev/null || git rev-parse HEAD)
          echo "sha=$LATEST_SHA" >> $GITHUB_OUTPUT
          echo "Latest SHA: $LATEST_SHA"
      - name: Configure Git merge strategy
        run: |
          git config --global merge.ours.driver true
          git config user.name "github-actions[bot]"
          git config user.email "github-actions[bot]@users.noreply.github.com"
      - name: Set up JDK 21
        uses: actions/setup-java@v4
        with:
          java-version: "21"
          distribution: "temurin"
          cache: maven
      - name: Install Checkstyle
        run: |
          curl -L -o checkstyle.jar https://github.com/checkstyle/checkstyle/releases/download/checkstyle-10.20.0/checkstyle-10.20.0-all.jar

      - name: Run Checkstyle
        run: |
          java -jar checkstyle.jar \
            -c .github/google_checks.xml \
            -f xml \
            -o checkstyle-result.xml \
            $(git ls-files '*.java' | grep -v 'Tester\.java$')

      - name: Install reviewdog
        uses: reviewdog/action-setup@v1

      - name: Report with reviewdog
        id: reviewdog
        run: |
          reviewdog -name="checkstyle" \
            -reporter=github-check \
            -filter-mode=nofilter \
            -level=error \
            -fail-level=any \
            -f=checkstyle < checkstyle-result.xml
        env:
          GITHUB_TOKEN: ${{ secrets.GITHUB_TOKEN }}
          REVIEWDOG_GITHUB_API_TOKEN: ${{ secrets.GITHUB_TOKEN }}
          GITHUB_SHA: ${{ steps.get_sha.outputs.sha }}

      - name: Build with Maven
        if: always()
        run: mvn -B package --file pom.xml -Dcheckstyle.skip=true
      - name: Calculate Grade
        if: always()
        id: grade
        run: |
          # Parse test results from Maven Surefire XML reports
          if [ -d "target/surefire-reports" ]; then
            TESTS=$(grep -r "tests=" target/surefire-reports/TEST-*.xml | sed -n 's/.*tests="\([0-9]*\)".*/\1/p' | awk '{s+=$1} END {print s}')
            FAILURES=$(grep -r "failures=" target/surefire-reports/TEST-*.xml | sed -n 's/.*failures="\([0-9]*\)".*/\1/p' | awk '{s+=$1} END {print s}')
            ERRORS=$(grep -r "errors=" target/surefire-reports/TEST-*.xml | sed -n 's/.*errors="\([0-9]*\)".*/\1/p' | awk '{s+=$1} END {print s}')
            SKIPPED=$(grep -r "skipped=" target/surefire-reports/TEST-*.xml | sed -n 's/.*skipped="\([0-9]*\)".*/\1/p' | awk '{s+=$1} END {print s}')
            
            # Default to 0 if values are empty
            TESTS=${TESTS:-0}
            FAILURES=${FAILURES:-0}
            ERRORS=${ERRORS:-0}
            SKIPPED=${SKIPPED:-0}
            
            # Calculate passed tests
            PASSED=$((TESTS - FAILURES - ERRORS - SKIPPED))
            
            # Calculate grade (percentage)
            if [ $TESTS -gt 0 ]; then
              GRADE=$((PASSED * 100 / TESTS))

              if [ "${{ steps.reviewdog.outcome }}" = "failure" ]; then
                GRADE=$((GRADE - 25))
              fi
              
            else
              GRADE=0
            fi
            
            echo "Total Tests: $TESTS"
            echo "Passed: $PASSED"
            echo "Failed: $FAILURES"
            echo "Errors: $ERRORS"
            echo "Skipped: $SKIPPED"
            echo "Grade: ${GRADE}%"
            
            # Set outputs for other steps
            echo "tests=$TESTS" >> $GITHUB_OUTPUT
            echo "passed=$PASSED" >> $GITHUB_OUTPUT
            echo "failed=$FAILURES" >> $GITHUB_OUTPUT
            echo "errors=$ERRORS" >> $GITHUB_OUTPUT
            echo "skipped=$SKIPPED" >> $GITHUB_OUTPUT
            echo "grade=$GRADE" >> $GITHUB_OUTPUT
          else
            echo "No test results found"
            echo "tests=0" >> $GITHUB_OUTPUT
            echo "passed=0" >> $GITHUB_OUTPUT
            echo "failed=0" >> $GITHUB_OUTPUT
            echo "errors=0" >> $GITHUB_OUTPUT
            echo "skipped=0" >> $GITHUB_OUTPUT
            echo "grade=0" >> $GITHUB_OUTPUT
          fi
      - name: Create Grade Badge
        if: always()
        run: |
          mkdir -p .github/badges
          GRADE="${{ steps.grade.outputs.grade }}"
          if [ $GRADE -ge 90 ]; then
            COLOR="brightgreen"
          elif [ $GRADE -ge 70 ]; then
            COLOR="green"
          elif [ $GRADE -ge 50 ]; then
            COLOR="yellow"
          else
            COLOR="red"
          fi
          # Create badge with link to GitHub Actions run
          REPO_NAME="${{ github.event.repository.name }}"
          OWNER="${{ github.repository_owner }}"
          RUN_ID="${{ github.run_id }}"
          TEST_REPORT_URL="https://github.com/${OWNER}/${REPO_NAME}/actions/runs/${RUN_ID}"
          echo "[![Grade](https://img.shields.io/badge/Grade-${GRADE}%25-${COLOR})](${TEST_REPORT_URL})" > .github/badges/grade.md
          echo "[ðŸ“Š View Test Reports](${TEST_REPORT_URL})" > .github/badges/test_report.md
      - name: Publish Test Report
        uses: dorny/test-reporter@v2
        if: always()
        with:
          name: Maven Test Results
          path: target/surefire-reports/*.xml
          reporter: java-junit
          fail-on-error: false
      # Collect all Java files (excluding *Tester.java)
      - name: Collect Java files
        if: always()
        run: |
          find . -name "*.java" -not -name "*Tester.java" -type f > java_files.txt
      # Run AI Review with ChatGPT
      - name: AI Review with ChatGPT
        if: always() && steps.grade.outputs.grade > 0 && steps.reviewdog.outcome == 'success'
        id: ai_review
        run: |
          mkdir -p .github/badges

          # Build combined content of all Java files
          ALL_CONTENT=""
          for file in $(cat java_files.txt); do
            FILE_CONTENT=$(cat "$file")
            ALL_CONTENT="${ALL_CONTENT}--- File: $file ---\n${FILE_CONTENT}\n\n"
          done

          # Escape for JSON
          ALL_CONTENT_ESCAPED=$(echo "$ALL_CONTENT" | sed 's/"/\\"/g' | sed ':a;N;$!ba;s/\n/\\n/g')

          # Send all files in a single request with retry logic
          MAX_RETRIES=3
          RETRY_COUNT=0
          RESPONSE=""

          # Check if API key is set
          if [ -z "${{ secrets.OPENAI_API_KEY }}" ]; then
            echo "âŒ ERROR: OPENAI_API_KEY secret is not configured"
            echo "Please add your OpenAI API key to GitHub repository secrets"
            RESPONSE="âš ï¸ **AI Review Unavailable** (-20 points): OpenAI API key not configured. Please add OPENAI_API_KEY to repository secrets, or ask your teacher, Barak, to add a key for you."
            echo "## AI Code Review" > .github/badges/review.md
            echo "" >> .github/badges/review.md
            echo "$RESPONSE" >> .github/badges/review.md
            
            # Apply penalty for missing AI review
            ORIGINAL_GRADE="${{ steps.grade.outputs.grade }}"
            ADJUSTED_GRADE=$((ORIGINAL_GRADE - 20))
            if [ $ADJUSTED_GRADE -lt 0 ]; then
              ADJUSTED_GRADE=0
            fi
            
            # Update grade badge
            if [ $ADJUSTED_GRADE -ge 90 ]; then
              COLOR="brightgreen"
            elif [ $ADJUSTED_GRADE -ge 70 ]; then
              COLOR="green"
            elif [ $ADJUSTED_GRADE -ge 50 ]; then
              COLOR="yellow"
            else
              COLOR="red"
            fi
            
            REPO_NAME="${{ github.event.repository.name }}"
            OWNER="${{ github.repository_owner }}"
            RUN_ID="${{ github.run_id }}"
            TEST_REPORT_URL="https://github.com/${OWNER}/${REPO_NAME}/actions/runs/${RUN_ID}"
            echo "[![Grade](https://img.shields.io/badge/Grade-${ADJUSTED_GRADE}%25-${COLOR})](${TEST_REPORT_URL}) *(Original: ${ORIGINAL_GRADE}%, Penalties: -20)*" > .github/badges/grade.md
            
            echo "adjusted_grade=$ADJUSTED_GRADE" >> $GITHUB_OUTPUT
            exit 0
          fi

          while [ $RETRY_COUNT -lt $MAX_RETRIES ]; do
            RAW_RESPONSE=$(curl -s https://api.openai.com/v1/chat/completions \
              -H "Content-Type: application/json" \
              -H "Authorization: Bearer ${{ secrets.OPENAI_API_KEY }}" \
              -d "{
                 \"model\": \"gpt-4o\",
                 \"messages\": [
                  {\"role\": \"system\", \"content\": \"You are a senior Java reviewer and computer science teacher. Provide accurate, constructive feedback suitable for high school students.\\n\\nTHIS IS A LEARNING EXERCISE.\\n- DO NOT provide code solutions or example implementations.\\n- Explain WHAT must be changed, not HOW to code it.\\n- DO NOT flag code that is already correct.\\n- ONLY report real issues that REQUIRE code changes.\\n- When unsure, DO NOT penalize.\"},
                  {\"role\": \"user\", \"content\": \"Review the following Java files for a student assignment.\\n\\nABSOLUTE RULES:\\n1) DO NOT review or comment on any files ending with 'Tester.java'.\\n2) DO NOT provide code or partial solutions.\\n3) ONLY describe WHAT needs to change, never HOW.\\n4) Keep feedback short, clear, and encouraging for high school students.\\n\\nFOCUS ON:\\n- Missing functionality required to pass tests\\n- Duplicate code (CRITICAL)\\n- Magic numbers\\n- Syntax, indentation, and brace usage\\n- Readability and logic flow\\n\\nMAGIC NUMBERS:\\n- Magic numbers are NOT allowed outside main()\\n- Use named final constants instead\\n- Magic numbers ARE allowed inside main() for testing\\n\\nBRACES:\\n- ALL if / else / for / while statements MUST use {}\\n- Missing braces is a violation\\n\\nCOPY CONSTRUCTORS:\\n- The copy constructor does not perform validation; it only copies existing field values and creates new objects for class-type fields.\\n- DO NOT flag copy constructors for lack of validation - this is correct behavior.\\n\\nDUPLICATE CODE â€” STRICT & MANDATORY (HIGHEST PRIORITY):\\n\\nâ— ANY DUPLICATE LOGIC MUST BE FLAGGED â—\\n\\nEXCEPTIONS:\\n- FlightA and FlightB are separate main programs and MAY have duplicate code between them. DO NOT flag duplicate code between FlightA.java and FlightB.java.\\n- Repeated validation logic (e.g., range checks with default values) across DIFFERENT CLASSES is considered acceptable and is NOT duplicate code. DO NOT flag this.\\n\\nYou MUST actively search for ALL forms of duplicate code, including:\\n\\n1) IDENTICAL CODE\\n- Same condition\\n- Same instruction\\n- Same calculation\\n\\n2) LOGICALLY EQUIVALENT CODE (EVEN IF TEXT IS DIFFERENT)\\n- Same condition written with different spacing or formatting\\n- Same range checks using the same constants\\n\\n3) SIMILAR CONDITIONS\\n- Conditions that check the same rule or constraint\\n- Range checks enforcing the same limits\\n- Validation logic enforcing the same business rule\\n\\n4) SIMILAR INSTRUCTIONS\\n- Same assignments performed in multiple places\\n- Same method calls performed after similar checks\\n- Same logical steps repeated in different methods\\n\\n5) OPPOSITE METHODS\\n- Check the implementation of opposite methods. When two methods represent opposite operations (e.g., bigger / smaller, cheaper / morExpens), one method must be implemented by calling the other.\\n\\nMOST COMMON REQUIRED CHECK (MANDATORY):\\n- Compare ALL constructors against ALL setter methods WITHIN THE SAME CLASS\\n- If the SAME or SIMILAR validation logic appears in more than one place WITHIN THE SAME CLASS, it IS duplicate code\\n- Validation logic must exist in ONE place only WITHIN EACH CLASS\\n- EXCEPTION: Copy constructors are excluded from this check\\n\\nIf ANY duplicate logic is found:\\n- You MUST include âŒ **Duplicate Code** (-10 points recommended)\\n- Clearly state which methods contain duplicated or similar logic\\n- State that the shared logic must appear only once\\n\\nVALIDATION PROCESS â€” FOLLOW EXACTLY:\\n1) Read the Java code carefully\\n2) Compare logic, NOT formatting\\n3) Treat similar conditions and similar instructions as duplicate\\n4) Verify the duplication truly exists WITHIN THE SAME CLASS\\n5) ONLY flag issues that REQUIRE code changes\\n6) Cite the exact methods where duplication occurs\\n\\nCRITICAL ENFORCEMENT RULES:\\n- DO NOT mention code that is already correct\\n- DO NOT suggest best practices unless a change is required\\n- String literals (e.g., \\\"test1\\\") are NOT variable names\\n\\nSCORING SECTIONS (ONLY INCLUDE IF APPLICABLE):\\n- âŒ **Duplicate Code** (-10 points) â†’ REQUIRED if ANY duplicate logic exists\\n- âŒ **Magic Numbers** (-5 points) â†’ constants required outside main()\\n\\nNO ISSUES FOUND:\\n- Start with: âœ… **Code Quality: Excellent!**\\n- Keep response minimal\\n\\nIF PENALTIES APPLY:\\n- End with: Recommended adjusted grade: [original grade minus penalties]%\\n\\nWhen in doubt â€” DO NOT penalize.\\n\\nCode:\\n\\n$ALL_CONTENT_ESCAPED\"}
                ],
                \"max_tokens\": 4000,
                \"store\": true
              }")

            # Check for API errors first
            ERROR_MSG=$(echo "$RAW_RESPONSE" | jq -r '.error.message // empty')
            if [ -n "$ERROR_MSG" ]; then
              echo "API Error: $ERROR_MSG"
              echo "Full response: $RAW_RESPONSE"
            fi

            # Extract the content
            RESPONSE=$(echo "$RAW_RESPONSE" | jq -r '.choices[0].message.content // empty')

            # Check if response is not null or empty
            if [ -n "$RESPONSE" ]; then
              echo "API request successful"
              break
            fi

            RETRY_COUNT=$((RETRY_COUNT + 1))
            if [ $RETRY_COUNT -lt $MAX_RETRIES ]; then
              echo "API response was null/empty. Retrying in 5 seconds... (Attempt $((RETRY_COUNT + 1))/$MAX_RETRIES)"
              sleep 5
            else
              echo "API request failed after $MAX_RETRIES attempts"
              RESPONSE="âš ï¸ **AI Review Unavailable** (-20 points): API request failed. Please check back later."
            fi
          done

          echo "## AI Code Review" > .github/badges/review.md
          echo "" >> .github/badges/review.md
          echo "$RESPONSE" >> .github/badges/review.md

          # Check for violations and update grade
          CODING_STANDARD_PENALTY=0
          DUPLICATE_CODE_PENALTY=0
          MAGIC_NUMBERS_PENALTY=0
          AI_REVIEW_UNAVAILABLE_PENALTY=0

          if grep -q "âš ï¸ \*\*AI Review Unavailable\*\*" .github/badges/review.md; then
            AI_REVIEW_UNAVAILABLE_PENALTY=20
          fi

          if grep -q "âŒ \*\*Duplicate Code\*\*" .github/badges/review.md; then
            DUPLICATE_CODE_PENALTY=10
          fi

          if grep -q "âŒ \*\*Magic Numbers\*\*" .github/badges/review.md; then
            MAGIC_NUMBERS_PENALTY=5
          fi

          TOTAL_PENALTY=$((CODING_STANDARD_PENALTY + DUPLICATE_CODE_PENALTY + MAGIC_NUMBERS_PENALTY + AI_REVIEW_UNAVAILABLE_PENALTY))


          if [ $TOTAL_PENALTY -gt 0 ]; then
            ORIGINAL_GRADE="${{ steps.grade.outputs.grade }}"
            ADJUSTED_GRADE=$((ORIGINAL_GRADE - TOTAL_PENALTY))
            
            # Ensure grade doesn't go below 0
            if [ $ADJUSTED_GRADE -lt 0 ]; then
              ADJUSTED_GRADE=0
            fi
            
            # Determine color for adjusted grade
            if [ $ADJUSTED_GRADE -ge 90 ]; then
              COLOR="brightgreen"
            elif [ $ADJUSTED_GRADE -ge 70 ]; then
              COLOR="green"
            elif [ $ADJUSTED_GRADE -ge 50 ]; then
              COLOR="yellow"
            else
              COLOR="red"
            fi
            
            # Update grade badge with adjusted grade
            REPO_NAME="${{ github.event.repository.name }}"
            OWNER="${{ github.repository_owner }}"
            RUN_ID="${{ github.run_id }}"
            TEST_REPORT_URL="https://github.com/${OWNER}/${REPO_NAME}/actions/runs/${RUN_ID}"
            echo "[![Grade](https://img.shields.io/badge/Grade-${ADJUSTED_GRADE}%25-${COLOR})](${TEST_REPORT_URL}) *(Original: ${ORIGINAL_GRADE}%, Penalties: -${TOTAL_PENALTY})*" > .github/badges/grade.md
            
            # Set output for adjusted grade
            echo "adjusted_grade=$ADJUSTED_GRADE" >> $GITHUB_OUTPUT
          else
            # No penalties, adjusted grade equals original grade
            echo "adjusted_grade=${{ steps.grade.outputs.grade }}" >> $GITHUB_OUTPUT
          fi
      - name: GitHub Classroom Grader
        uses: baraksu-class-2026/manual-grading-command-grader@v1
        if: always()
        id: run-tests
        with:
          test-name: Junit And AI.
          score: ${{ steps.ai_review.outputs.adjusted_grade || steps.grade.outputs.grade }}
          max-score: 100
          pass-score: 85
      - name: Autograding Reporter
        if: always()
        uses: classroom-resources/autograding-grading-reporter@v1
        env:
          RUN-TESTS_RESULTS: "${{steps.run-tests.outputs.result}}"
        with:
          runners: run-tests
      # Update README with all badge contents (last step)
      - name: Update README with Badge
        if: always()
        run: |
          # Read the badge files content
          GRADE_CONTENT=$(cat .github/badges/grade.md)
          TEST_REPORT_CONTENT=$(cat .github/badges/test_report.md)

          # Check if review.md exists, if not create a default message
          if [ -f .github/badges/review.md ]; then
            REVIEW_CONTENT=$(cat .github/badges/review.md)
          else
            REVIEW_CONTENT=$'## AI Code Review\n\nâŒ **AI Hasn\'t Reviewed Your Work**\n\nYour submission was not sent for AI review because the basic requirements were not met.'
          fi

          # Create README with injected content
          cat > README.md << 'EOFMARKER'
          ## Grade

          EOFMARKER
          echo "$GRADE_CONTENT" >> README.md

          # Add Checkstyle status if it failed
          if [ "${{ steps.reviewdog.outcome }}" = "failure" ]; then
            REPO_NAME="${{ github.event.repository.name }}"
            OWNER="${{ github.repository_owner }}"
            RUN_ID="${{ github.run_id }}"
            CHECKSTYLE_REPORT_URL="https://github.com/${OWNER}/${REPO_NAME}/actions/runs/${RUN_ID}"
            cat >> README.md << 'EOFMARKER2'

          ## Coding Standards

          EOFMARKER2
            echo "âŒ **Coding Standard Failed (-25 points)** - [View Checkstyle Report](${CHECKSTYLE_REPORT_URL})" >> README.md
          fi

          cat >> README.md << 'EOFMARKER'

          ## Tests

          EOFMARKER
          echo "$TEST_REPORT_CONTENT" >> README.md

          cat >> README.md << 'EOFMARKER'

          EOFMARKER
          echo "$REVIEW_CONTENT" >> README.md
      # Commit and push all changes (final step)
      - name: Commit and Push All Changes
        if: always()
        run: |
          # Configure git
          git config user.name "github-actions[bot]"
          git config user.email "github-actions[bot]@users.noreply.github.com"

          # Pull latest changes BEFORE staging to avoid conflicts
          git pull --rebase origin ${{ github.ref_name }} || echo "Already up to date"

          # Stage all changed files (only if they exist)
          for file in README.md .github/badges/grade.md .github/badges/test_report.md .github/badges/review.md; do
            if [ -f "$file" ]; then
              git add "$file"
            fi
          done

          # Commit all changes
          git commit -m "Update README and badges [skip ci]" || echo "No changes to commit"

          # Push changes
          git push || echo "Nothing to push"
